{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2  (Due: 10/26/2022)\n",
    "\n",
    "COEN 281, Fall 2022  \n",
    "Professor Marwah\n",
    "\n",
    "---\n",
    "\n",
    "### Student name:\n",
    "### Student ID:\n",
    "### Student email:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this HW is to implement k-NN and cross-validation to find the best value of $k$ for a binary classification task. The task to diagnose breast cancer based on 30 numeric features. However, to keep things simple, we will only use two of those features. The output is binary: 0 benign, 1 malignant. In all there are 569 examples, which we will split into training and test sets. There are no missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the data set\n",
    "dat = sklearn.datasets.load_breast_cancer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following and run it to get a description of the data set\n",
    "#print(dat.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat is a dictionary with the data, let's see what keys it has\n",
    "dat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use two features: 'mean area' and 'mean concave points'\n",
    "ix1 = np.where(dat[\"feature_names\"] == \"mean area\")[0][0]\n",
    "ix2 = np.where(dat[\"feature_names\"] == \"mean concave points\")[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dat[\"data\"][:,(ix1,ix2)]\n",
    "Y = dat[\"target\"]\n",
    "\n",
    "# verify shape of X and Y\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# stats of the two features\n",
    "from scipy import stats\n",
    "st = stats.describe(X)\n",
    "print(\"Number of points: %i\" % st.nobs)\n",
    "print(\"range (min, max), X1: (%.2f, %.2f), X2: (%.2f, %.2f)\" % (st.minmax[0][0], st.minmax[1][0], st.minmax[0][1], st.minmax[1][1]))\n",
    "print(\"mean: %.2f, %.2f\" % (st.mean[0], st.mean[1]))\n",
    "print(\"variance: %.2f, %f\" % (st.variance[0], st.variance[1]))\n",
    "\n",
    "# Given the stats, is it a good idea to normalize the features?\n",
    "\n",
    "#\n",
    "# add code to normalize features (any method of normalization can be used)\n",
    "# note: you cannot use any libary funtion \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training set / test set\n",
    "#\n",
    "# usually you would do the split randomly; here for deterministic results, we assume the data \n",
    "# points are already shuffled and take the first 70% as training and the rest as test\n",
    "#\n",
    "nTot = X.shape[0]\n",
    "nTr = int(nTot*0.7)\n",
    "nTs = nTot - nTr\n",
    "\n",
    "Xtr = X[0:nTr,]\n",
    "Ytr = Y[0:nTr]\n",
    "\n",
    "Xts = X[nTr:nTot,]\n",
    "Yts = Y[nTr:nTot,]\n",
    "\n",
    "# verify shapes\n",
    "print(Xtr.shape, Ytr.shape, Xts.shape, Yts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the following functions for k-NN\n",
    "#\n",
    "#\n",
    "def knn_predict(Xtr, Ytr, Xts, k):\n",
    "    \"\"\"\n",
    "        input: Xtr - training examples input features, size nXd\n",
    "               Ytr - label (can assume to be binary 0/1), size nX1\n",
    "               Xts - test examples input features, for which labels (Yts) \n",
    "                     need to be predicted, size mXd\n",
    "               k   - k for the k-NN algo \n",
    "\n",
    "        output: Yts - 0/1 labes for Xts, size mX1\n",
    "\n",
    "         This function predicts the binary labels for Xts, given the training\n",
    "         data Xtr, Ytr and k, using the k-NN algorithm\n",
    "       \n",
    "    \"\"\"\n",
    "    \n",
    "    # compute in two steps\n",
    "    \n",
    "    # step 1: compute dist matrix between Xts and Xtr\n",
    "    #\n",
    "    dist = compute_dist_mat(Xtr, Xts)\n",
    "    \n",
    "    # step 2: use the dist matrix and use k-nn to find labels for Xts \n",
    "    # hint: function numpy.argsort may be useful\n",
    "    # in case of a tie, pick a class randomly\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "#  compute_dist_mat(Xtr, Xts)\n",
    "#\n",
    "#\n",
    "def compute_dist_mat(Xtr, Xts):\n",
    "    \"\"\"\n",
    "     input: Xtr - training examples, size nXd\n",
    "            Xts - test examples, size mXd\n",
    "\n",
    "     output: L2 distance matrix mXn\n",
    "\n",
    "      if Xtr is nXd, and Xts is mXd, this function returns a matrix of size mXn with the L2 distances; the (i,j) \n",
    "        entry of the matrix is the L2 distance between ith test and jth training example     \n",
    "    \n",
    "    \"\"\"    \n",
    "    # YOUR CODE HERE\n",
    "    # Note: you cannot use any library functions \n",
    "    \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1 (30 points): Fill-in code for normalizing features, and the above two functions to implement k-NN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2 (20 points): Run your k-NN implementation on the test data set. Use k=5. Compute accuracy, recall and precision of the test data set (do not use python library functions to compute these). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem 2 solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "Priblem 3 (30 points): Now we will implement 5-fold cross-validation to find the best value of $k$. And then using that value of $k$, re-run k-NN on the test data set. (This is adapted from a past Stanford cs231n assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "k_choices = [1, 3, 5, 7, 9, 11, 13, 15, 20, 30, 40, 50, 75, 100]\n",
    "\n",
    "X_train_folds = []\n",
    "y_train_folds = []\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Split up the training data into folds. After splitting, X_train_folds and    #\n",
    "# y_train_folds should each be lists of length num_folds, where                #\n",
    "# y_train_folds[i] is the label vector for the points in X_train_folds[i].     #\n",
    "# Hint: Look up the numpy array_split function.                                #\n",
    "################################################################################\n",
    "pass\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "\n",
    "# A dictionary holding the accuracies for different values of k that we find\n",
    "# when running cross-validation. After running cross-validation,\n",
    "# k_to_accuracies[k] should be a list of length num_folds giving the different\n",
    "# accuracy values that we found when using that value of k.\n",
    "k_to_accuracies = {}\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Perform k-fold cross validation to find the best value of k. For each        #\n",
    "# possible value of k, run the k-nearest-neighbor algorithm num_folds times,   #\n",
    "# where in each case you use all but one of the folds as training data and the #\n",
    "# last fold as a validation set. Store the accuracies for all fold and all     #\n",
    "# values of k in the k_to_accuracies dictionary.                               #\n",
    "################################################################################\n",
    "pass\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "\n",
    "# Print out the computed accuracies\n",
    "for k in sorted(k_to_accuracies):\n",
    "    for accuracy in k_to_accuracies[k]:\n",
    "        print('k = %d, accuracy = %f' % (k, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plot the raw observations\n",
    "for k in k_choices:\n",
    "    accuracies = k_to_accuracies[k]\n",
    "    plt.scatter([k] * len(accuracies), accuracies)\n",
    "\n",
    "# plot the trend line with error bars that correspond to standard deviation\n",
    "accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "accuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\n",
    "plt.title('Cross-validation on k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Cross-validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 4 (20 points): Based on the cross-validation results above, choose the best value for $k$. Repeat problem 2 with this $k$ (using the entire training data set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#problem 4 solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: these extra credit problems are optional and only increase your score marginally. \n",
    "\n",
    "Extra Credit Problem 1 (5 points): Plot decision boundaries for the best $k$, similar to how it is done here:\n",
    "http://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html\n",
    "\n",
    "Extra Credit Problem 2 (5 points): In problem 1 above, re-write the compute_dist_mat() function with no loops. That may seem non-intuitive, but it is possible to compute the L2 distances using matrix operations (matrix multiplication, addition, etc.) without explicitly doing the double for loop. The advantage of using matrix operations is that they are highly optimized and enable \"vectorization\", and for such computations can give 10-100x speed improvements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
